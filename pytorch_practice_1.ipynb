{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRcYW++y2CgYNx5bV41XKW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjeetCodes/BuildWithAjeet/blob/master/pytorch_practice_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJbzilzuBmjM",
        "outputId": "fb23c40c-5bfd-4049-b1df-d1d4b3c2d564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "! pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "COIVhMogCiUm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üß† PYTORCH PRACTICE SET ‚Äî Autograd & Loss Function Mastery**"
      ],
      "metadata": {
        "id": "nulQh2JBCsNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚öôÔ∏è LEVEL 1 ‚Äî Basic Autograd\n",
        "\n",
        "**Goal**: Understand how gradients work for simple equations."
      ],
      "metadata": {
        "id": "Jum6rrleCvnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1Ô∏è‚É£ : Simple equation\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "y = x**2 + 4*x + 2\n",
        "\n",
        "# use backpropegation\n",
        "y.backward()\n",
        "print(\"x.grad =\", x.grad)\n",
        "\n",
        "# ‚úèÔ∏è Task:\n",
        "# Predict gradient manually (dy/dx = ?) and verify output.\n",
        "\n",
        "# Expected understanding:\n",
        "# gradient = 2x + 4 = 10 when x=3\n",
        "\n",
        "# calculate manually derivative\n",
        "\"\"\"\n",
        "dy/dx = 2x+4 so where x = 3\n",
        "2.3 + 4 = 10\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HaH3wvgtDAdL",
        "outputId": "42743d6d-f0b7-43cb-d493-996d75a18f7f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.grad = tensor(10.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndy/dx = 2x+4 so where x = 3 \\n2.3 + 4 = 10\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚öôÔ∏è LEVEL 2 ‚Äî Multi-variable Function\n",
        "\n",
        "**Goal**: Understand gradient calculation for multiple tensors."
      ],
      "metadata": {
        "id": "50UpOdJwELIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "# Q2Ô∏è‚É£ : Multi-variable expression\n",
        "z = x**2 * y + 3*y + 1\n",
        "\n",
        "z.backward()\n",
        "print(\"dz/dx =\", x.grad)\n",
        "print(\"dz/dy =\", y.grad)\n",
        "\n",
        "# ‚úèÔ∏è Task:\n",
        "# Manually calculate:\n",
        "# dz/dx = 2x*y\n",
        "# dz/dy = x^2 + 3\n",
        "# Verify both with output.\n",
        "# calculation\n",
        "\"\"\"dz/dy = x**2 + 3 = 7\n",
        "f'x = 2xy = 2.2.3 = 12 \"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "35wJGUhcEO5Z",
        "outputId": "b80e803a-0c8d-41b2-b407-f8deae936cc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dz/dx = tensor(12.)\n",
            "dz/dy = tensor(7.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"dz/dy = x**2 + 3 = 7\\nf'x = 2xy = 2.2.3 = 12 \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚öôÔ∏è LEVEL 3 ‚Äî MSE Loss Manual Calculation\n",
        "\n",
        "**Goal**: Understand how loss functions are implemented internally."
      ],
      "metadata": {
        "id": "3MZQl0geKKpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "y_true = torch.tensor([3.0, 5.0, 7.0])\n",
        "y_pred = torch.tensor([2.5, 5.5, 6.0])\n",
        "\n",
        "# Manual MSE\n",
        "manual_loss = torch.mean((y_pred - y_true)**2)\n",
        "\n",
        "# Using built-in MSELoss\n",
        "criterion = nn.MSELoss()\n",
        "torch_loss = criterion(y_pred, y_true)\n",
        "\n",
        "print(\"Manual Loss:\", manual_loss.item())\n",
        "print(\"Torch Loss :\", torch_loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfEfEp1IKQaH",
        "outputId": "8d91ac5c-e8e5-485c-cd23-733ae47c148a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Loss: 0.5\n",
            "Torch Loss : 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚öôÔ∏è LEVEL 4 ‚Äî Gradient Descent Simulation\n",
        "\n",
        "**Goal**: Use autograd to update parameter w to minimize loss (w‚àítarget)¬≤"
      ],
      "metadata": {
        "id": "5ipV0wwjKPev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(0.0, requires_grad=True)\n",
        "target = 5.0\n",
        "lr = 0.1\n",
        "\n",
        "for step in range(10):\n",
        "    loss = (w - target)**2  # loss function\n",
        "    loss.backward()         # compute gradient\n",
        "\n",
        "    with torch.no_grad():\n",
        "        w -= lr * w.grad    # update parameter\n",
        "\n",
        "    w.grad.zero_()          # clear gradient\n",
        "\n",
        "    print(f\"Step {step+1}: w={w.item():.3f}, loss={loss.item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2pOABAZK09A",
        "outputId": "43b047cd-79e4-44b2-b742-223a438bbc6a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: w=1.000, loss=25.000\n",
            "Step 2: w=1.800, loss=16.000\n",
            "Step 3: w=2.440, loss=10.240\n",
            "Step 4: w=2.952, loss=6.554\n",
            "Step 5: w=3.362, loss=4.194\n",
            "Step 6: w=3.689, loss=2.684\n",
            "Step 7: w=3.951, loss=1.718\n",
            "Step 8: w=4.161, loss=1.100\n",
            "Step 9: w=4.329, loss=0.704\n",
            "Step 10: w=4.463, loss=0.450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚öôÔ∏è LEVEL 5 ‚Äî Combine Model + Loss + Optimizer\n",
        "\n",
        "**Goal**: Understand the full learning loop using nn.Linear, nn.MSELoss, and optimizer."
      ],
      "metadata": {
        "id": "jucDlZFyNXTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1.0, 2.0], [2.0, 3.0], [3.0, 4.0]])\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orSKCcf_OC7x",
        "outputId": "620d1a42-d86a-404f-9190-d4bf1b5912f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "# Training Data\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "y_true = torch.tensor([[2.0], [4.0], [6.0]])  # y = 2x\n",
        "\n",
        "# Model\n",
        "model = nn.Linear(1, 1)\n",
        "\n",
        "# Loss + Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(10):\n",
        "    y_pred = model(x)               # Forward\n",
        "    loss = criterion(y_pred, y_true)  # Loss\n",
        "    optimizer.zero_grad()           # Clear grad\n",
        "    loss.backward()                 # Compute grad\n",
        "    optimizer.step()                # Update weights\n",
        "\n",
        "    print(f\"step {epoch+1}: Loss = {loss.item():.4f} Y Pred = {y_pred.tolist()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsbl6ix0NbpN",
        "outputId": "0cc631a4-543c-4daa-9ebb-c3c31e9b7b1d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1: Loss = 31.1449 Y Pred = [[-0.46095573902130127], [-1.1356985569000244], [-1.810441493988037]]\n",
            "step 2: Loss = 0.5552 Y Pred = [[2.9770960807800293], [4.713265419006348], [6.449434280395508]]\n",
            "step 3: Loss = 0.1811 Y Pred = [[2.5843143463134766], [4.07035493850708], [5.556395530700684]]\n",
            "step 4: Loss = 0.1683 Y Pred = [[2.610629081726074], [4.13705587387085], [5.663482666015625]]\n",
            "step 5: Loss = 0.1603 Y Pred = [[2.591538667678833], [4.126286029815674], [5.6610331535339355]]\n",
            "step 6: Loss = 0.1526 Y Pred = [[2.577800750732422], [4.124067306518555], [5.6703338623046875]]\n",
            "step 7: Loss = 0.1454 Y Pred = [[2.5638580322265625], [4.12099552154541], [5.678133010864258]]\n",
            "step 8: Loss = 0.1385 Y Pred = [[2.550309181213379], [4.118096828460693], [5.68588399887085]]\n",
            "step 9: Loss = 0.1319 Y Pred = [[2.5370795726776123], [4.1152567863464355], [5.69343376159668]]\n",
            "step 10: Loss = 0.1256 Y Pred = [[2.5241684913635254], [4.112486362457275], [5.700803756713867]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Excercise**"
      ],
      "metadata": {
        "id": "h2B4u9HRVhUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üß© Exercise 1: Basic Autograd (Single Variable)\n",
        "\n",
        "**Goal**: Understand how PyTorch automatically computes gradients.\n",
        "### üëâ Task:\n",
        "#### Write a code to do the following:\n",
        "- Create a tensor x = 3.0 with requires_grad=True\n",
        "- Define an equation\n",
        "   Y = x^2 + 4x +1\n",
        "- Compute the gradient using .backward()\n",
        "- Print the gradient using x.grad"
      ],
      "metadata": {
        "id": "rdY5zvNCVbXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "y = x**2 + 4*x + 1\n",
        "y.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opUcVz61WEb0",
        "outputId": "7c7a2376-7ee3-4dc4-b05f-4f7b659c15d7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß© Exercise 2: Multi-variable Autograd\n",
        "\n",
        "**Goal**: Calculate gradients when a function has two input tensors.\n",
        "\n",
        "##üß† Task:\n",
        "- Create two scalar tensors (x, y), define an expression involving both (use multiplication and addition),\n",
        "- perform backward propagation, and print gradients for both variables."
      ],
      "metadata": {
        "id": "OpElavooXZyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = torch.tensor(3.0, requires_grad=True)\n",
        "z = x**2 * y + 3*y +1\n",
        "# f'x = 2xy = 2*2*3 = 12\n",
        "# f'y = x**2 + 3 = 7\n",
        "z.backward()\n",
        "print(f\"x grad = {x.grad} ,y grad = {y.grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLKKElZtWRcV",
        "outputId": "4bad5f2a-eaaa-48cf-a892-c77315f5d67a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x grad = 12.0 ,y grad = 7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß© Exercise 3: Manual Loss vs Built-in MSELoss\n",
        "\n",
        "**Goal**: Compare manually calculated Mean Squared Error (MSE) with PyTorch‚Äôs nn.MSELoss() output.\n",
        "\n",
        "##üß† Task:\n",
        "\n",
        "- Create two 1D tensors ‚Äî one for actual values (y_true), one for predictions (y_pred)\n",
        "(take at least 3 values each, slightly different).\n",
        "\n",
        "- Compute MSE manually using the formula:\n",
        "    MSE=1/n‚Äã‚àë(ypred‚Äã‚àíytrue‚Äã)2\n",
        "- Then, use PyTorch‚Äôs built-in loss function:\n",
        "criterion = nn.MSELoss()\n",
        "and calculate loss using:\n",
        "loss = criterion(y_pred, y_true)\n",
        "\n",
        "- Print both manual loss and PyTorch loss values."
      ],
      "metadata": {
        "id": "U-gm2JrMfGh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_true_pred = torch.tensor([[2.0], [4.0], [6.0]])\n",
        "y_true = torch.tensor([[4.0], [8.0], [12.0]])\n",
        "\n",
        "manual_loss = torch.mean((y_pred - y_true)**2)\n",
        "# manual_loss\n",
        "ct = torch.nn.MSELoss()\n",
        "loss = ct(y_pred, y_true)\n",
        "# loss\n",
        "print(f\"manula loss {manual_loss}, loss = {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGrXN_tHYGw4",
        "outputId": "4757f7db-9efb-4e52-97ff-31e878b3b3cd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "manula loss 18.990238189697266, loss = 18.990238189697266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß© Exercise 4: Gradient Descent Simulation\n",
        "\n",
        "**Goal**: Understand how autograd + gradient descent together minimize loss step by step.\n",
        "\n",
        "##üß† Task:\n",
        "\n",
        "- Create a scalar weight w with some initial value (e.g., 0.0) and requires_grad=True.\n",
        "\n",
        "- Define a simple target (e.g., 5.0).\n",
        "\n",
        "- Define the loss function: loss = (w- target)**2\n",
        "- Call .backward() to compute the gradient.\n",
        "\n",
        "- Manually update w using gradient descent rule inside torch.no_grad() block:\n",
        "\n",
        "  w = w - \\text{learning_rate} \\times w.grad\n",
        "\n",
        "- Reset gradients using w.grad.zero_() after each step.\n",
        "\n",
        "- Repeat this process for about 10 steps and print values of w and loss after each step."
      ],
      "metadata": {
        "id": "KTbaDtL_iE6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(0.0, requires_grad=True)\n",
        "target = 5\n",
        "loss = torch.nn.MSELoss()\n",
        "for step in range(10):\n",
        "  loss = (w - target)**2\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    w -= 0.1 * w.grad\n",
        "  w.grad.zero_()\n",
        "\n",
        "  print(f\"step - {step}, weight - {w.item():.2f}, loss - {loss.item():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M15cWQM0hES7",
        "outputId": "6c4b3e58-8d4e-4ec2-c879-81663dfdb5f4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step - 0, weight - 1.00, loss - 25.00\n",
            "step - 1, weight - 1.80, loss - 16.00\n",
            "step - 2, weight - 2.44, loss - 10.24\n",
            "step - 3, weight - 2.95, loss - 6.55\n",
            "step - 4, weight - 3.36, loss - 4.19\n",
            "step - 5, weight - 3.69, loss - 2.68\n",
            "step - 6, weight - 3.95, loss - 1.72\n",
            "step - 7, weight - 4.16, loss - 1.10\n",
            "step - 8, weight - 4.33, loss - 0.70\n",
            "step - 9, weight - 4.46, loss - 0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß© Exercise 5 ‚Äî Model + Loss + Optimizer (Full Training Loop)\n",
        "\n",
        "**üéØ Goal**:\n",
        "Learn how forward pass, loss, backward pass, and optimizer work together inside PyTorch‚Äôs training loop."
      ],
      "metadata": {
        "id": "1CAvQG--lAcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_input = torch.tensor([[2.0], [4.0], [6.0]])\n",
        "y_true = torch.tensor([[4.0], [8.0], [12.0]])\n",
        "\n",
        "# initialize model\n",
        "model = torch.nn.Linear(1,1)\n",
        "\n",
        "# Loss + Optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for step in range(10):\n",
        "  y_pred = model(x_input)\n",
        "  loss = criterion(y_pred, y_true)  # Loss\n",
        "  optimizer.zero_grad()           # Clear grad\n",
        "  loss.backward()                 # Compute grad\n",
        "  optimizer.step()                # Update weights\n",
        "  print(f\"step {step+1}: Loss = {loss.item():.4f}, Y_pred = {y_pred.detach().T.tolist()}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLFEvVfElD0-",
        "outputId": "5ca391e7-d5c0-412b-9c70-09cbd6931f94"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1: Loss = 173.6702, Y_pred = [[-2.434326171875, -4.282798767089844, -6.1312713623046875]]\n",
            "step 2: Loss = 172.2888, Y_pred = [[-2.4043264389038086, -4.232799053192139, -6.061271667480469]]\n",
            "step 3: Loss = 170.9130, Y_pred = [[-2.3743295669555664, -4.182804107666016, -5.991279602050781]]\n",
            "step 4: Loss = 169.5430, Y_pred = [[-2.3443379402160645, -4.132818222045898, -5.921298980712891]]\n",
            "step 5: Loss = 168.1788, Y_pred = [[-2.314354181289673, -4.082845211029053, -5.851336479187012]]\n",
            "step 6: Loss = 166.8206, Y_pred = [[-2.284379720687866, -4.032887935638428, -5.78139591217041]]\n",
            "step 7: Loss = 165.4685, Y_pred = [[-2.2544171810150146, -3.98294997215271, -5.711483001708984]]\n",
            "step 8: Loss = 164.1225, Y_pred = [[-2.22446870803833, -3.933035373687744, -5.641602516174316]]\n",
            "step 9: Loss = 162.7827, Y_pred = [[-2.194535732269287, -3.8831472396850586, -5.57175874710083]]\n",
            "step 10: Loss = 161.4493, Y_pred = [[-2.164621353149414, -3.83328914642334, -5.501956939697266]]\n"
          ]
        }
      ]
    }
  ]
}